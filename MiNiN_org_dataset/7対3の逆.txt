7:3 = posi:negaの経験則を無視したデータセットを使ってみると、、、

[■顔認識用のposiデータ収集に気を取られすぎて]
NIN2_128_DET1xの学習データが9:1 = posi:negaぐらいになっている
この状況で、ほぼ100%なAPが得られるけれど、カメラからの実画面ではFPが多すぎ;-<
Threshold==90%とかに設定すると、FPは消えるがTPも減る
？
Threshold==90%とposi:nega=9:1って相関があるのでは？

[■3:7 = posi:negaでNIN3_128_DET1x4を試す]
新たにYOLOを参考にしたNIN3_128_DET1x4を作る
試しにテキトーな学習データで試すと、、、結構イケてる
FPが少ない感じだし、Threshold==25%~30%程度になっている;-)

使用した学習データでは、
 3:7 = posi:nega
こんな比率で、まるで7:3経験則の逆になっていた

で、posi:negaの比率とThresholdの相関がありそうと考えるようになってきた

データ読み込みのログは、
      662 bedroom
       705 livingroom
       731 kitchen
      2688 weight
      2688 spatial_envelope_256x256_static_8outdoorcategories
      7707 wiki
     15531 indoorCVPR_09
こんな感じ:-)

全部で15531+2688+7707=25926、内posi=7707でposiが30%、negaが70%
ビッタシ 3:7 = posi:negaで経験則の逆

*DET1x4なモデルは最終出力が4chで1x1なfeature-mapだからposi-nega比率計算は合っている

[■YOLOの誤差重み付けはどうかと]
YOLOの誤差重み付けでは、10倍と5倍とかな重みをposiな場所に掛けて、posi-nega比率のアンバランスを
是正していると想像している
YOLOv1の最終出力は30chで7x7なfeature-map(そこに１人か２人しか映っていない)ので基本的にnegaデータが多い
対象物が1つしか映っていないと、posiの48倍だけnegaデータができることになるので、是正しているのかと

YOLOでは基本的にposiよりnegaなデータが多いが、NIN*_128_DET1x4ではposi-nega比率は
学習データ内のposi-nega比率そのものになるから是正はいらないと考えた
なので、是正は学習データ内のposi-nega比率をイーブンとか7:3とかにする必要がある

[■NIN3_128_DET1x4での誤差重み付け]
誤差の重み付けは、
3/7 == posi画像数/(posi+nega画像数)
にするのがベター？

