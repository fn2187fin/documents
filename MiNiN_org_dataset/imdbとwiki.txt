
「機械学習はデータセットが命」

★人物検出はむずかしいく中々まともな成果が出ない;-<
①YOLOを見習い全身画像のアノテーションデータであるVOCデータセットで学習試すが成果が出ない

②VOCデータセットのように全身画像の中心を正解とすると、
　腹、足、頭、手とか顔とかのバラバラな特徴から全身の位置と領域という一つの正解を推定する問題
　6分類していることになっていないか、問題が矛盾していないか気になる
　足、全身は柱、手は葉っぱなどとの区別がつきにくいので、それらを分類できて初めて全身推定できるのかも
　柱などは人と一緒に写り込んでいるケースが多いので、足や全身と混乱させる厄介物
　葉っぱは小さいので写り込んでも影響は少ない、実際問題、手の認識率は高い

③顔の中心位置だけを正解とすると問題が簡単になる
　顔は特徴が似通っているので、顔の位置と大きさを認識する問題は人物検出としては最も易しいかも
　帽子、サングラス、ヘルメット、マスクをしたものを人物と理解させるもっと容易なマーキングの手法もある
　最低これらができないと、足や手から全身を推定するのはムリ

よって全身画像から顔位置推定を行うデータセットを探して適用してみた
顔位置推定ができて初めて手や足の位置推定かもしれない

[■IMDB-WIKIデータセット]
年齢推定するタスク向けの↓こんなものが見つかった
"IMDB-WIKI ? 500k+ face images with age and gender labels"
https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/

460,723枚がimdb(46万枚ってスゴっ)
 62,328枚がwiki(から取ってるらしい)
顔部分を囲むアノテーションデータになっている

年齢当てタスクが本来の目的
imdbとimdb_crop
wikiとwiki_crop
それぞれ顔の部分の周囲を刈り取ったのが*_cropで画像はほぼ正方形
imdbとwikiは刈り取る前の全身の画像
全部で300GB以上の画像データ

matフォーマットでアノテーションが提供されている
読み方は、
meta = scipy.io.loadmat('wiki.mat')
で読めて、辞書になってる
meta.keys()
['wiki', '__version__', '__header__', '__globals__']

さらに、理解不能だけど
full_paths     = meta[mat_key][0,0]['full_path'][0]
face_locations = meta[mat_key][0,0]['face_location'][0]
face_scores    = meta[mat_key][0,0]['face_score'][0]
face_scores_2nd= meta[mat_key][0,0]['second_face_score'][0]
↑これでjpgファイルパスや顔のアノテーションデータなどにアクセスできる

座標表示の説明では↓
img(face_location(2):face_location(4),face_location(1):face_location(3),:))
つまり(lx,ly,rx,ry)になっているらしい

[■このデータセットを使った学習方針]
顔のどアップを学習(ほぼ画像中心に顔がある)
顔の位置を学習

[■VOCとLFWでの学習との違い]
LFWではアノテーションされていないので、自前の固定の顔枠で学習させるしかない
VOCでは顔の位置のアノテーションデータではなく、人体全体のアノテーションなので画像中心には特徴が無いケースも多く問題が難しい
imdbとwikiでは、顔の位置だけが学習対象なので常に特徴があり問題が簡単になるハズ

[■使えるデータを選ぶ]
本番のカメラ入力を考えて縦長な画像はムシ
score>10.とかNANとか-inf(全身画像)はムシすると
wiki_crop:13,436枚
imdb_crop:27,103枚
だいぶ減る;-<
※cropが荒いものもあるが使う;-0

[■学習のお試し]
wiki_cropとwikiで21,175枚で学習する
顔領域が比率で0.1とかな小さい顔も教師データから消えてしまわないようにtrainer_det.pyを修正
python trainBD_det.py -m NIN2_128_DET --augment -g 0

カメラ画像での推定の味見は、結構いい感じで気になる点は、
①道路面などランダムな画像部分を拾っている、言い換えれば↓
※適合率(precision)：検索結果の中にどの程度正解が含まれるかを示す
※再現率(  recall )：正解のうち、どの程度が検索にヒットするかを示す
として適合率が低く、再現率が高い感じで、正解は見逃さないが、間違いも入る

precision = (検索結果∩正解)/検索結果(正解の見逃し率の逆)
recall    = (検索結果∩正解)/正解    (間違いの混入率の逆)
※見逃し率を下げると間違い混入率が上がるという当たり前の関係がある

調和平均
F値 = (2 x precision x recall) / (precision + recall)

[■学習の本番]

[■ネットワーク構成]
評価は感触が頼り
①64x64入力4x4x2出力のNiNの3層
　VOCデータセットでの試行を開始したが、出力が偶数かつ4x4では見た目が悪いし認識も怪しい感触

②128x128入力5x5x2出力のNiNの6層
　VOCデータセットでの試行を開始したが、認識が怪しい感触;-<もっと大きなネットが必要かもしれない
　VOCデータセットを諦めてIMDB+WIKIで顔位置学習すると、再現率が高い感触
