NIN3_128_DET1x4での認識

学習データセットでは、99％近いPrecisionが得られても、カメラ画像を入力すると、、、まるで認識がヘンテコ;-<

posi:nega = 3:7な学習モデルを使って、WebからFlickr-API利用して画像を取り、認識をかけてみるが、、、
結構認識率は高い(と感じる)、カメラ画像の低認識率は一体何が原因なのか
(predict_det.pyのバグがあり、カメラ画像での認識処理自体に間違いがあったが、それだけが原因でもなさそう)

カメラ画像と写真の違いは何か？
結論：YOLOの前処理にあるディストーション処理はカメラ画像での認識処理に効果が大きいと考えられる

[■学習時のaugmentationに秘密がある]
YOLOのaugmentコードを調べると、学習時にはaugment処理している
左右上下へのシフトとFlipで、ランダムな処理になっている
ランダムディストーションなる処理ではhue(色相)とsaturation(彩度),exposure(明度)をランダムに振っている
(色相／彩度／明度 = hue/saturation/exposure = 色合い／サチり／露出とも訳される)
Camera画像と写真の差異を意識したものなのかもしれないので、同等機能を試す

☆YOLOのディストーション処理の中身
まずランダムにhue/sat/expの値を決める
yolo.cfgファイルでhue/sat/exp = .1 / 1.5 / 1.5 と初期値が与えられる
hue = -hue ~ hue at randam つまり -0.1 ~ 0.1間でランダム
sat = 1~sat at random then return sat 50% randam, 1/sat 50% random
exp = 1~exp at random then return sat 50% randam, 1/sat 50% random
つまり 1 ~ 1.5間でランダムでさらに50%はその値を使い、50%は逆数を使う

HSV色空間へ変換
上で決めたhue/sat/expを使って、
彩度チャネルにsatを掛ける(計算結果に制限を与えない)
明度チャネルにexpを掛ける(計算結果に制限を与えない)
色相チャネルにhueを加え、1以上であれば1を引き、0以下であれば1を足す
1以上は1へ、0未満は0へ値を制限する
RGB色空間へ変換

ディストーション処理を実装し、処理後の画像をみると、絵の鮮やかさが落ちてモノトーン調な画像に変換された
YOLOでは画像の読み込み時にディストーション処理しているらしく、処理する／しないのフラグは見当たらない
train/val/testの全てのフェーズでディストーション処理しているらしい

☆ディストーション処理を入れて学習を試す
YOLOとは異り、train/valでディストーション処理し、テスト時にはディストーション処理を入れない
すると学習検証は進むが、テストロスが減らない状態
train/valではディストーションの入った画像を学習し、テストではディストーション無しな画像を推定しているので当然かも

☆15000枚の学習データ(posi-nega = 5:5)でNIN3_128_DET1x4を学習した結果
・APは93%程度
・カメラ画像入力での顔検出性能が高くなった感じ
・スレッショルドが90%と高くすると背景との分離ができる
しかし、テストロスーtrainロス曲線を見ると、過学習症状を示している
データ数が不足している可能性が高い

☆15000枚の学習データ(posi:nega = 5:5)でNIN3_128_DET1x4を学習した結果、その2ロス関数修正
confidenceの誤差に対して、r,x,yは正解が1ではないので異るロス関数を試す
Xのロス関数 ＝ (X - X')*1/X平均     X正解、X'推定値
X平均値が小さいほど推定値との差を大きく考える
これは正解１.０で推定０.５のケースと、正解０.１で推定０.４のケースがあった場合、
差分では、０.５違いと０.３違いと評価されるが、倍数的には、2倍違いと4倍違いとなる
試行した結果、X、Y、R誤差に多少の違いが出ている感覚はあるがあまりかわらない

☆手ぶれ効果を入れて学習を試す
OpenCVのblur関数(平均移動)は手ぶれ現象に近い画像を生成でそうなので試した
左右上下への手ぶれをランダムに発生させて画像にエフェクトさせた
結果的には少々ロバストな推定になったかもしれない

☆評価関数について
YOLOなどの物体検出での評価はmAPが一般的とはいうが、
m:mean クラスの評価の平均
A:Average 平均
P:Precision 適合率
ここでNIN3_128_DET14は、クラスが1つなのでmAP=APだろう
そしてR、X、Yの推定なので、IoUは簡単に求まる
IoU = (x-x'-r-r')*(y-y'-r-r')
U   = r*r + r'*r'
∴ ratio = IoU/U
r,x,y(正解)とr',x',y'(推定値)からratioへ変換して、APscoreを求めれば良い

☆カメラ画像の推定で露出の調整は必要か？
BGR2HSVで露出を上げる前処理を入れるとカメラ画像の認識精度が良くなる感じ:-)
学習時のディストーションと同じ処理だが、カメラ画像では背景が明く、前景が暗いケースも発生するが、
このとき、認識精度が落るようなので、その対策
Wikiなど公開学習データの画像は人が浮き上がるほどキレイに写った写真が多いが、カメラ画像はもっと汚く、
これがカメラ画像の認識率を下げる原因の1つかもしれない;-<

☆誤認識の多い画像
森(非常に間違う)
しゃのかかった女性写真
☆中心座標の推定
x,y,rのそれぞれの誤差は大きい

