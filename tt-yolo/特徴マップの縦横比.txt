特徴マップの縦横比

学習は224x224のMultiScale Training(random=1)

      VGA     f.map-size
W     640          224        288         224         352
H     480          224        224         160         288
比    4:3          1:1        9:7         7:5        11:9
倍   1.33         1.00       1.28        1.40        1.22
mAP          49.8/53.7  51.1/57.2   47.4/48.8   53.1/61.0
Bn               0.640      0.823       0.457       1.294

カメラ画像サイズに合わせて特徴マップの縦横比を変えることで、
　クラスミスが増える
　検出ミスが増える
　小さな物体のRecallが上がる

学習時の縦横比を4:3ベース

大きく写るもの(飛行機とかソファーとか)と小さく写るもの(人やネコとか)の検出に難あり

演算量を下げて認識性能は落ちるが、VOC問題での対策が考えられるか、、、
大きく写るもの：aeroplane, boat, bus, diningtable, sofa, train
小さく写るもの：bird, botle, cat, chair, cow, dog,horse, person...

aeroplaneのFPが目立つ
⇒get_region_boxes()アルゴで、クラス０の扱いが特殊(バグ?)なことが原因か

・大きく写るものにFPが多いのであれば除去
・小さく写るものにFNが多いのであればマップサイズ拡大

Scalable-HDL実装で、特徴マップサイズは長方形にできるか？
