■DNNの理論面は非常に曖昧で、研究者でも制御はカン

制御不能な性能を信用することは難しいが、制御可能なルールベースは処理速度が遅いし、認識性能もDNNより低い

だからDNNを使いたくはなるが、DNNは認識アルゴが理論的に立証されておらず、何をどこまで認識できるのかは出来高払いになっている

Recall, Precision, F値などを制御し、フロントエンドとして必要な性能を出せれば、DNNと他の認識技術を併用する可能性はある

当たるも八卦だけれど、速く高いRecallが必要な分野では使えるかもしれない

そこそこ速く、高いPrecisionが必要な分野では100%APではないので使えない

速さとF値を制御できれば何かに使えるかもしれないってこと

しかし、このユースケースでは、遅いが認識率100%な他のバックエンド認識器が必須になるが、そのような認識器は存在しない

■バイナリーなDNNを試すと、認識率の低下が目立つ

tinyなネットワークでprecision==80%だとしても、ユーザーはカメラ画像を見て、「あら、誤検出してる！」「これ、未検出だよね」

言いたい放題

ヒトを超える認識性能がなければ、ユーザーは納得しない

このようなマーケットに対して、「FPGAで高速化したんで検出性能が5％落ちますよ」と言えば、「あら、誤検出してる！、FPGAの問題だよね」

Floatで80％認識率だって納得しないユーザーが、75％を見せられたら、、、言いたい放題

■Floatでどこまで認識性能を求めるか

まずユーザーが納得する認識性能が分かったとする、、、VOCでPrecision:80％以上だろうか

歴代のDarknet記録、、、

Model  	Train 	              Test 	mAP 	FLOPS  	FPS
Old YOLO 	VOC 2007+2012 	2007 	63.4 	40.19 Bn 	45
SSD300 	VOC 2007+2012 	2007 	74.3 	- 	       46 	
SSD500 	VOC 2007+2012 	2007 	76.8 	- 	       19 
YOLOv2 	VOC 2007+2012 	2007 	76.8 	34.90 Bn 	67 
YOLOv2ー
 544x544 	VOC 2007+2012 	2007 	78.6 	59.68 Bn 	40
Tiny YOLO 	VOC 2007+2012 	2007 	57.1 	 6.97 Bn 	207

その観点で見てみると、そんな検出器は無い！

tiny-YOLOだと、、、57%！と書かれている

では75%以上で手を打とう、、、なぜか構造が超簡単なYOLOv2しかない

手元の2007 VOC testで追試すると、

yolov2-tiny-voc.cfg 62.5%(recall 81.61%)
yolov2-voc.cfg      73.4%(recall 90.04%)

手元のデータで、yolov2-vocでは75%が出なかったが、どちらもrecallは高い値を示している

75%を目指せばターゲットはYOLOv2かSSD300になるが、YOLOv2の構造は、
layer     filters    size              input                output
    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32
    1 max          2 x 2 / 2   416 x 416 x  32   ->   208 x 208 x  32
    2 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64
    3 max          2 x 2 / 2   208 x 208 x  64   ->   104 x 104 x  64
    4 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128
    5 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64
    6 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128
    7 max          2 x 2 / 2   104 x 104 x 128   ->    52 x  52 x 128
    8 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256
    9 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128
   10 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256
   11 max          2 x 2 / 2    52 x  52 x 256   ->    26 x  26 x 256
   12 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512
   13 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256
   14 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512
   15 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256
   16 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512
   17 max          2 x 2 / 2    26 x  26 x 512   ->    13 x  13 x 512
   18 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024
   19 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512
   20 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024
   21 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512
   22 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024
   23 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024
   24 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024
   25 route  16
   26 conv     64  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x  64
   27 reorg              / 2    26 x  26 x  64   ->    13 x  13 x 256
   28 route  27 24
   29 conv   1024  3 x 3 / 1    13 x  13 x1280   ->    13 x  13 x1024
   30 conv    125  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 125
   31 region

22層のConvolutionになってる

バイナリ化しても相当重いネットワークだろう

そして73.4%からバイナリ化で10％精度が落ちれば、65%前後となりFloatのtiny-yolo並みになる

ついでに言えば、tiny-yoloの認識率は、、、いくら速くてもマーケットには相手にされないだろう

このような精度低下と速度向上のトレードオフを考えると、FloatのままFPGA化した方が良いのかもしれない

FPGA化によって1桁程度速くなるならば、大きなネットワークをFPGA化するメリットがあるかもしれないが、
routeやreorgなどはバイナリ化できるのだろうか

