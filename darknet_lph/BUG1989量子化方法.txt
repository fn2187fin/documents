BUG1989の量子化方法

①量子化変換処理はpythonで書かれていて、caffeを動かして量子化する仕掛け
②ncnnという中華製FrameWorkで試されている
　モバイル向け推論専用機で
　　c++で書かれていて、androidやiosで動く
　　caffe/pytorch/mxnet/onnx modelsが読める
　　neon最適化が掛かっている
　　BLASなどは使っていない
　　オブジェクトが小さい～500KB
　　8bit量子化サポート
　　layerの拡張が可能？
③TencentというIT企業で開発したもの？

■weights量子化は単純
ただし、group化？といっているテクニックは理解に苦しむが、実行例ではgroup==1

■activation量子化
NewとOldバージョンがあり、
New：caffeのbottom(入力)画像の量子化
Old：caffeのtop(出力)画像の量子化
らしい

activation_quantize():
すべてのcalibration画像について推論し、各出力層ごとに数値分布を合計して、層数分の分布図を作る
threshold := 128～2048で振る
  各層について、分布モデル(threshold)を作る
  推論から求めた分布と、thresholdから作った分布モデルの相互エントロピーが最も小さいとき、そのthresholdが回答

層ごとにthresholdが求まり、これをカメラ画像推論する

■層ごとのthresholdについて
C = A * B
においてA:カーネル行列、B:画像行列とすると、Aは推論中一定なので1回の量子化値を使い回せる
一方、Bは推論のたびに変わるので、推論のたびに量子化する

　▼速度メリット
新たな画像を推論するたびに、thresholdを求める処理は、
　画素値範囲 = [全画素値のmax,minを求めて、絶対値の大きな方]
  factor     = 128/画素値範囲
  全画素値  /= factor
　C = A * B
  全画素値  *= factor
になり、画像を3回走査することになる

対して、calibrationでは、統計上有効なfactorが事前に求まっているから、
  全画素値  /= factor
　C = A * B
  全画素値  *= factor
になり、画像を2回走査することになる

この画像走査は、各レイヤーについて処理は発生するので、
10レイヤーならば、30回走査と20回走査になり、レイヤーが増えるほどcalibration方式はゲインがある

　▼精度メリット
カーネルのweightは、たくさんの画像を推論した結果から求まり、対応するダイナミックレンジを持ってる
同様な考え方で、たくさんの画像の推論結果を合算してActivation結果のヒストグラムを作り、
それによって画像のthresholdを決めて画像を量子化することは至極自然な考え方である
よって、各画像ごとに画素値の最大値で量子化する場合に比べ、精度が上がる可能性があることは否めない
定量的には分からないが

ある画像では、画素値が0～5などに限定されていた場合、factor=128/5で量子化すべきか？
weightsは、画素値が0～255など広く分布していた画像群に対して学習したものであるに係わらずだ
だから、たくさんの画像に対して推論を再度行い、weightsの素性に合わせて画像も量子化する
