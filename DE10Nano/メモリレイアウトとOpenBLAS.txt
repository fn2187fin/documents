メモリレイアウトとOpenBLASのCblasColMajor/cblasRowMajor

行列の積和算：SGEMMは、
  C = αA・B + βC
の計算をする

計算される元の行列A、Bは、
  A：row-matrix
  B：col-matrix
と呼ばれるらしい。BLASではA、B、Cどれも1次元配列で行列を表現する

この時、2次元行列をメモリ上の1次元配列で表現する場合、2つの方法がある

  row-major(行優先)配置
  col-major(列優先)配置

例えば、row-matrixが
  ________
  |1, 2, 3|
  |4, 5, 6|
  ~~~~~~~~
で、これを1次元配列に配置する時、

  row-major 1次元配列表現 1,2,3,4,5,6
  col-major 1次元配列表現 1,4,2,5,3,6

になる

cblas_sgemm()はどちらの行列表現も扱うことができて、
A、B、Cがすべて行優先：cblas_sgemm(CblasRowMajor,..A..B..C..) A、Bを行優先で読み、積和算をして、Cに行優先で書き込む
A、B、Cがすべて列優先：cblas_sgemm(CblasColMajor,..A..B..C..) A、Bを列優先で読み、積和算をして、Cに列優先で書き込む

Aを列優先、Bを行優先、Cを列優先の様な積和算はできないらしく、すべて行優先かすべて列優先

■オリジナルなDarknetのConvolution演算
DarknetのYOLO計算では、A, B, Cはすべて行優先での表現
オリジナルなDarknetのgemm(TA,TB,...)では、TA,TBの値により、
[0,0]: gemm_nn：A、Bを行優先で読み、積和算をして、Cに行優先で書き込む
[1,1]: gemm_tt：A、Bを列優先で読み、積和算をして、Cに行優先で書き込む
[0,1]: gemm_nt：Aを行優先で読み、Bを列優先で読み、積和算をして、Cに行優先で書き込む
[1,0]: gemm_tn：Aを列優先で読み、Bを行優先で読み、積和算をして、Cに行優先で書き込む
となっていて、Cは常に行優先であり、OpenBLASのcblas_sgemm()とは仕様が違う;-P

よってConvolution演算では、
・im2col()は入力画像からcol-matrix(B)をrow-majorメモリレイアウトで作る
・Aは手を加えず、そのままrow-majorとして読む
としてdarknetのgemm()で積和演算する

A：入力チャネル＊カーネル＊カーネル＊出力チャネル
B：入力チャネル＊カーネル＊カーネル＊画像
C：出力チャネル＊画像
をdarknetのgemm(0,0,..A..B..C..)で演算するので、結果としてCは行優先配置になる

■im2rowを使うConvolution演算
im2colでcol-matrixをrow-majorで作る演算に対して、im2rowでrow-matrixを作る演算が存在し、かつ、im2colより演算速度が速い
・im2rowは入力画像からrow-matrix(A)をcol-majorメモリレイアウトで作る
・Bはdarknetのweightsを、そのままcol-majorとして読む

A：入力チャネル＊カーネル＊カーネル＊画像
B：入力チャネル＊カーネル＊カーネル
C：出力チャネル＊画像
をcblas_sgemm(CblasColMajor,..A..B..C..)で演算するので、結果としてCは列優先配置になる

発見：
※結果のC行列は列優先配置ではあるが、そのまま行優先配置として読めば、画像(W*H)＊出力チャネルとして読むことができる。
これは、

行優先な入力画像レイアウト
(H * W * ピクセル) (H * W * ピクセル) ・・(H * W * ピクセル)
列優先なC行列レイアウト
(H * W * ピクセル) (H * W * ピクセル) ・・(H * W * ピクセル)
でメモリレイアウトは同一なので、

C = net.input            // 行優先な入力画像レイアウト
while(true):
  A = im2row(C)          // Cを行優先として読む
  C = cblas_sgemm(A,B)   // 列優先なC行列レイアウト

と連続して計算できる

■im2rowはオリジナルのDarknet gemm()では使うことができない
ところが、Darknetのオリジナルgemm()ではC行列が常に行優先であるため、連続して計算すると結果を誤まる

行優先な入力画像レイアウト
(H * W * ピクセル) (H * W * ピクセル) ・・(H * W * ピクセル)
行優先なC行列レイアウト
(out_c * ピクセル) (out_c * ピクセル) ・・(out_c * ピクセル)
でメモリレイアウトは異なるので、連続計算で答えを誤まる

